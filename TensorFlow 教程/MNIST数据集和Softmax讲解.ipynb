{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Testing Accurancy0.8901\n",
      "Iter 1, Testing Accurancy0.9025\n",
      "Iter 2, Testing Accurancy0.9074\n",
      "Iter 3, Testing Accurancy0.9117\n",
      "Iter 4, Testing Accurancy0.9127\n",
      "Iter 5, Testing Accurancy0.9149\n",
      "Iter 6, Testing Accurancy0.917\n",
      "Iter 7, Testing Accurancy0.917\n",
      "Iter 8, Testing Accurancy0.9187\n",
      "Iter 9, Testing Accurancy0.9199\n",
      "Iter 10, Testing Accurancy0.9211\n",
      "Iter 11, Testing Accurancy0.9215\n",
      "Iter 12, Testing Accurancy0.9213\n",
      "Iter 13, Testing Accurancy0.9218\n",
      "Iter 14, Testing Accurancy0.9222\n",
      "Iter 15, Testing Accurancy0.9217\n",
      "Iter 16, Testing Accurancy0.9236\n",
      "Iter 17, Testing Accurancy0.9242\n",
      "Iter 18, Testing Accurancy0.9229\n",
      "Iter 19, Testing Accurancy0.924\n",
      "Iter 20, Testing Accurancy0.9244\n"
     ]
    }
   ],
   "source": [
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少批次\n",
    "n_batch= mnist.train.num_examples // batch_size\n",
    "\n",
    "\n",
    "#定义 placeholder 后面可以给x，y 赋值\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建神经网络\n",
    "W= tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "\n",
    "#二次代价函数 线性回归时使用\n",
    "#loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#交叉熵代价函数 输出为 s 型函数 使用交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)) \n",
    "#梯度向量法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.3).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#结果存放在布尔列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#求准确率 转换类型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "     sess.run(init)\n",
    "     for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iter '+ str(epoch)+', Testing Accurancy'+ str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二次代价函数\n",
    "Iter 0, Testing Accurancy0.8591\n",
    "Iter 1, Testing Accurancy0.8817\n",
    "Iter 2, Testing Accurancy0.8923\n",
    "Iter 3, Testing Accurancy0.8963\n",
    "Iter 4, Testing Accurancy0.9012\n",
    "Iter 5, Testing Accurancy0.9048\n",
    "Iter 6, Testing Accurancy0.9051\n",
    "Iter 7, Testing Accurancy0.9074\n",
    "Iter 8, Testing Accurancy0.9085\n",
    "Iter 9, Testing Accurancy0.91\n",
    "Iter 10, Testing Accurancy0.9115\n",
    "Iter 11, Testing Accurancy0.9134\n",
    "Iter 12, Testing Accurancy0.9136\n",
    "Iter 13, Testing Accurancy0.9142\n",
    "Iter 14, Testing Accurancy0.9147\n",
    "Iter 15, Testing Accurancy0.9157\n",
    "Iter 16, Testing Accurancy0.9158\n",
    "Iter 17, Testing Accurancy0.9169\n",
    "Iter 18, Testing Accurancy0.9167\n",
    "Iter 19, Testing Accurancy0.9172\n",
    "Iter 20, Testing Accurancy0.9182\n",
    "\n",
    "#交叉熵\n",
    "Iter 0, Testing Accurancy0.8901\n",
    "Iter 1, Testing Accurancy0.9025\n",
    "Iter 2, Testing Accurancy0.9074\n",
    "Iter 3, Testing Accurancy0.9117\n",
    "Iter 4, Testing Accurancy0.9127\n",
    "Iter 5, Testing Accurancy0.9149\n",
    "Iter 6, Testing Accurancy0.917\n",
    "Iter 7, Testing Accurancy0.917\n",
    "Iter 8, Testing Accurancy0.9187\n",
    "Iter 9, Testing Accurancy0.9199\n",
    "Iter 10, Testing Accurancy0.9211\n",
    "Iter 11, Testing Accurancy0.9215\n",
    "Iter 12, Testing Accurancy0.9213\n",
    "Iter 13, Testing Accurancy0.9218\n",
    "Iter 14, Testing Accurancy0.9222\n",
    "Iter 15, Testing Accurancy0.9217\n",
    "Iter 16, Testing Accurancy0.9236\n",
    "Iter 17, Testing Accurancy0.9242\n",
    "Iter 18, Testing Accurancy0.9229\n",
    "Iter 19, Testing Accurancy0.924\n",
    "Iter 20, Testing Accurancy0.9244\n",
    "\n",
    "\n",
    "\n",
    "#提高准确率：修改参数 神经隐藏层神经元  初始化W，b 修改  梯度下降法 学习率的修改 训练次数修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
